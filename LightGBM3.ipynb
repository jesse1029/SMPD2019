{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1217\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\m1217\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import pickle\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import time, datetime\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import gc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import jieba, pdb\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "# load stopwords set\n",
    "stopword_set = set()\n",
    "with open('jieba_dict/stopwords.txt','r', encoding='utf-8') as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_set.add(stopword.strip('\\n'))\n",
    "\n",
    "model = word2vec.Word2Vec.load(\"word2vec2.model\")\n",
    "\n",
    "\n",
    "def create_dictionaries(p_model):\n",
    "    gensim_dict = Dictionary()\n",
    "    gensim_dict.doc2bow(p_model.wv.vocab.keys(), allow_update=True)\n",
    "    w2indx = {v: k + 1 for k, v in gensim_dict.items()}  # 词语的索引，从1开始编号\n",
    "    w2vec = {word: model[word] for word in w2indx.keys()}  # 词语的词向量\n",
    "    return w2indx, w2vec\n",
    "\n",
    "def Convert_orderid(x):\n",
    "    return str(x).strip('\\n')\n",
    "\n",
    "def Convert_Date(x):\n",
    "    Year='20'+x[-2:]\n",
    "    Month=month[x[-6:-3]]\n",
    "    Day=x[:-7]\n",
    "    date1 = pd.to_datetime(Year+'-'+Month+'-'+Day)\n",
    "    return date1\n",
    "\n",
    "def Date2Ticks(x):\n",
    "    Year='20'+x[-2:]\n",
    "    Month=month[x[-6:-3]]\n",
    "    Day=x[:-7]\n",
    "    date1 = str(Year+'/'+Month+'/'+Day)\n",
    "    return time.mktime(datetime.datetime.strptime(date1, \"%Y/%m/%d\").timetuple())\n",
    "\n",
    "index_dict, word_vectors= create_dictionaries(model)\n",
    "output = open(\"wordwmbedding.pkl\", 'wb')\n",
    "pickle.dump(index_dict, output)  # 索引字典\n",
    "pickle.dump(word_vectors, output)  # 词向量字典\n",
    "output.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 296237)\n"
     ]
    }
   ],
   "source": [
    "df_train_1 = pd.read_csv(\"myTrain3.csv\")\n",
    "df_result_1 = pd.read_csv(\"myTest3.csv\")\n",
    "\n",
    "\n",
    "used_columns=['order_id','tick_diff', 'Source_1', 'Source_2', 'Unit', 'deal_or_not',\n",
    "'people_amount', 'Begin_Tick','days', 'Order_Tick', 'Area', 'SubLine', 'price','PreDays','Begin_Date_Weekday', \n",
    "'Order_Date_Weekday', 'Return_Date_Weekday', 'fly_t', 'fly_date',\n",
    "\"src_airport\", \"arrive_t\", \"arrive_date\", \"dst_airport\",'pred0','pred1','pred2','pred3','pred4','pred5','pred6', 'pred7','product_name']\n",
    "\n",
    "df_train_1 = df_train_1[used_columns]\n",
    "df_result_1 = df_result_1[used_columns]\n",
    "\n",
    "myPred = []\n",
    "for i in range(8):\n",
    "    myPred.append(df_train_1['pred%d'%(i)].values.tolist())\n",
    "myPred = np.asarray(myPred)\n",
    "print(myPred.shape)\n",
    "predFeat = []\n",
    "for i in range(len(myPred[0,:])):\n",
    "    predFeat.append([np.max(myPred[:,i]), np.percentile(myPred[:,i], 75), \n",
    "                     np.median(myPred[:,i]), np.percentile(myPred[:,i],25),np.min(myPred[:,i])]\n",
    "                   )\n",
    "train_feat=np.asarray(predFeat)\n",
    "\n",
    "myPred = []\n",
    "for i in range(8):\n",
    "    myPred.append(df_result_1['pred%d'%(i)].values.tolist())\n",
    "myPred = np.asarray(myPred)\n",
    "predFeat = []\n",
    "for i in range(len(myPred[0,:])):\n",
    "    predFeat.append([np.max(myPred[:,i]), np.percentile(myPred[:,i], 75), \n",
    "                     np.median(myPred[:,i]), np.percentile(myPred[:,i],25),\n",
    "                   np.min(myPred[:,i])])\n",
    "test_feat=np.asarray(predFeat)\n",
    "\n",
    "for i in range(8):\n",
    "    del df_result_1['pred%d'%(i)]\n",
    "    del df_train_1['pred%d'%(i)]\n",
    "\n",
    "Y=df_train_1['deal_or_not'].values.tolist()\n",
    "swX = (df_train_1['product_name']).values.tolist()\n",
    "del df_train_1['deal_or_not'] \n",
    "del df_train_1['product_name']\n",
    "del df_train_1['order_id']\n",
    "X = df_train_1.values.tolist()\n",
    "\n",
    "swrx = (df_result_1['product_name']).values.tolist()\n",
    "rid = df_result_1['order_id'].values.tolist()\n",
    "del df_result_1['product_name']\n",
    "del df_result_1['deal_or_not'] \n",
    "del df_result_1['order_id'] \n",
    "rx = df_result_1.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sX, Y =np.asarray(X), np.asarray(Y)\n",
    "X=np.concatenate([sX, train_feat], axis=1)\n",
    "rx = np.asarray(rx)\n",
    "rx=np.concatenate([rx, test_feat], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def text_to_index_array(p_new_dic, p_sen):  # 文本转为索引数字模式\n",
    "    new_sentences = []\n",
    "    for sen in p_sen:\n",
    "        new_sen = []\n",
    "        for word in str(sen):\n",
    "            try:\n",
    "                new_sen.append(p_new_dic[word])  # 单词转索引数字\n",
    "            except:\n",
    "                new_sen.append(0)  # 索引字典里没有的词转为数字0\n",
    "        new_sentences.append(new_sen)\n",
    "\n",
    "    return np.array(new_sentences)\n",
    "\n",
    "\n",
    "wX = text_to_index_array(index_dict, swX)\n",
    "wrx = text_to_index_array(index_dict, swrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296237, 86)\n",
      "(99736, 86)\n",
      "[8046. 8801.    0.    0.]\n"
     ]
    }
   ],
   "source": [
    "wX = sequence.pad_sequences(wX, maxlen=60)\n",
    "wrx = sequence.pad_sequences(wrx, maxlen=60)\n",
    "\n",
    "\n",
    "X=np.concatenate([X, wX], axis=1)\n",
    "rx=np.concatenate([rx, wrx], axis=1)\n",
    "# xlen=len(X)\n",
    "# from sklearn.preprocessing import normalize\n",
    "# Xtmp=normalize(np.concatenate([X, rx], axis=0),norm='max', axis=0)\n",
    "# X=Xtmp[:xlen]\n",
    "# rx=Xtmp[xlen:]\n",
    "\n",
    "print(X.shape)\n",
    "print(rx.shape)\n",
    "\n",
    "print(X[5,-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index: [     0      1      2 ... 296233 296234 296236] ,Val Index: [    15     37     46 ... 296213 296215 296235]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.672377\tvalid_1's auc: 0.659163\n",
      "[100]\ttraining's auc: 0.675841\tvalid_1's auc: 0.661932\n",
      "[150]\ttraining's auc: 0.678353\tvalid_1's auc: 0.662137\n",
      "[200]\ttraining's auc: 0.681063\tvalid_1's auc: 0.663636\n",
      "[250]\ttraining's auc: 0.683699\tvalid_1's auc: 0.665103\n",
      "[300]\ttraining's auc: 0.685877\tvalid_1's auc: 0.666259\n",
      "[350]\ttraining's auc: 0.688775\tvalid_1's auc: 0.667245\n",
      "[400]\ttraining's auc: 0.691481\tvalid_1's auc: 0.668121\n",
      "[450]\ttraining's auc: 0.694026\tvalid_1's auc: 0.669205\n",
      "[500]\ttraining's auc: 0.696192\tvalid_1's auc: 0.670145\n",
      "[550]\ttraining's auc: 0.69834\tvalid_1's auc: 0.670933\n",
      "[600]\ttraining's auc: 0.701232\tvalid_1's auc: 0.671754\n",
      "[650]\ttraining's auc: 0.703774\tvalid_1's auc: 0.67277\n",
      "[700]\ttraining's auc: 0.706593\tvalid_1's auc: 0.673647\n",
      "[750]\ttraining's auc: 0.708885\tvalid_1's auc: 0.674214\n",
      "[800]\ttraining's auc: 0.710626\tvalid_1's auc: 0.674815\n",
      "[850]\ttraining's auc: 0.712664\tvalid_1's auc: 0.675045\n",
      "[900]\ttraining's auc: 0.714904\tvalid_1's auc: 0.675591\n",
      "[950]\ttraining's auc: 0.716583\tvalid_1's auc: 0.67597\n",
      "[1000]\ttraining's auc: 0.718378\tvalid_1's auc: 0.676317\n",
      "[1050]\ttraining's auc: 0.720215\tvalid_1's auc: 0.676674\n",
      "[1100]\ttraining's auc: 0.721763\tvalid_1's auc: 0.677223\n",
      "[1150]\ttraining's auc: 0.723483\tvalid_1's auc: 0.677654\n",
      "[1200]\ttraining's auc: 0.72514\tvalid_1's auc: 0.677927\n",
      "[1250]\ttraining's auc: 0.726554\tvalid_1's auc: 0.678086\n",
      "[1300]\ttraining's auc: 0.728163\tvalid_1's auc: 0.678307\n",
      "[1350]\ttraining's auc: 0.729712\tvalid_1's auc: 0.678557\n",
      "[1400]\ttraining's auc: 0.731143\tvalid_1's auc: 0.678564\n",
      "[1450]\ttraining's auc: 0.732808\tvalid_1's auc: 0.678737\n",
      "[1500]\ttraining's auc: 0.734233\tvalid_1's auc: 0.678874\n",
      "[1550]\ttraining's auc: 0.735825\tvalid_1's auc: 0.67905\n",
      "[1600]\ttraining's auc: 0.737132\tvalid_1's auc: 0.679297\n",
      "[1650]\ttraining's auc: 0.738717\tvalid_1's auc: 0.679519\n",
      "[1700]\ttraining's auc: 0.740303\tvalid_1's auc: 0.679828\n",
      "[1750]\ttraining's auc: 0.741475\tvalid_1's auc: 0.680188\n",
      "[1800]\ttraining's auc: 0.742562\tvalid_1's auc: 0.680584\n",
      "[1850]\ttraining's auc: 0.743808\tvalid_1's auc: 0.680606\n",
      "[1900]\ttraining's auc: 0.745135\tvalid_1's auc: 0.680792\n",
      "[1950]\ttraining's auc: 0.746235\tvalid_1's auc: 0.681028\n",
      "[2000]\ttraining's auc: 0.747293\tvalid_1's auc: 0.681269\n",
      "[2050]\ttraining's auc: 0.748601\tvalid_1's auc: 0.681471\n",
      "[2100]\ttraining's auc: 0.749765\tvalid_1's auc: 0.681647\n",
      "[2150]\ttraining's auc: 0.750817\tvalid_1's auc: 0.681784\n",
      "[2200]\ttraining's auc: 0.752119\tvalid_1's auc: 0.682163\n",
      "[2250]\ttraining's auc: 0.753232\tvalid_1's auc: 0.68235\n",
      "[2300]\ttraining's auc: 0.75427\tvalid_1's auc: 0.682615\n",
      "[2350]\ttraining's auc: 0.755347\tvalid_1's auc: 0.682686\n",
      "[2400]\ttraining's auc: 0.756596\tvalid_1's auc: 0.682671\n",
      "[2450]\ttraining's auc: 0.757638\tvalid_1's auc: 0.682842\n",
      "[2500]\ttraining's auc: 0.758682\tvalid_1's auc: 0.683004\n",
      "[2550]\ttraining's auc: 0.759467\tvalid_1's auc: 0.683054\n",
      "[2600]\ttraining's auc: 0.76041\tvalid_1's auc: 0.683192\n",
      "[2650]\ttraining's auc: 0.761516\tvalid_1's auc: 0.683369\n",
      "[2700]\ttraining's auc: 0.762307\tvalid_1's auc: 0.683474\n",
      "[2750]\ttraining's auc: 0.763141\tvalid_1's auc: 0.683708\n",
      "[2800]\ttraining's auc: 0.764213\tvalid_1's auc: 0.683649\n",
      "[2850]\ttraining's auc: 0.765138\tvalid_1's auc: 0.683684\n",
      "[2900]\ttraining's auc: 0.766196\tvalid_1's auc: 0.683599\n",
      "[2950]\ttraining's auc: 0.767294\tvalid_1's auc: 0.683591\n",
      "Early stopping, best iteration is:\n",
      "[2759]\ttraining's auc: 0.763362\tvalid_1's auc: 0.683724\n",
      "Fold  1 AUC : 0.683727\n",
      "Train Index: [     0      1      2 ... 296233 296235 296236] ,Val Index: [     4      6     20 ... 296214 296220 296234]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.669958\tvalid_1's auc: 0.663579\n",
      "[100]\ttraining's auc: 0.674112\tvalid_1's auc: 0.667534\n",
      "[150]\ttraining's auc: 0.677135\tvalid_1's auc: 0.669251\n",
      "[200]\ttraining's auc: 0.680143\tvalid_1's auc: 0.670824\n",
      "[250]\ttraining's auc: 0.682922\tvalid_1's auc: 0.671983\n",
      "[300]\ttraining's auc: 0.685115\tvalid_1's auc: 0.673187\n",
      "[350]\ttraining's auc: 0.688103\tvalid_1's auc: 0.674622\n",
      "[400]\ttraining's auc: 0.69072\tvalid_1's auc: 0.675949\n",
      "[450]\ttraining's auc: 0.693575\tvalid_1's auc: 0.677195\n",
      "[500]\ttraining's auc: 0.696095\tvalid_1's auc: 0.678342\n",
      "[550]\ttraining's auc: 0.698411\tvalid_1's auc: 0.679264\n",
      "[600]\ttraining's auc: 0.700844\tvalid_1's auc: 0.68025\n",
      "[650]\ttraining's auc: 0.703446\tvalid_1's auc: 0.681456\n",
      "[700]\ttraining's auc: 0.706142\tvalid_1's auc: 0.682131\n",
      "[750]\ttraining's auc: 0.708662\tvalid_1's auc: 0.683232\n",
      "[800]\ttraining's auc: 0.710443\tvalid_1's auc: 0.683761\n",
      "[850]\ttraining's auc: 0.712451\tvalid_1's auc: 0.684374\n",
      "[900]\ttraining's auc: 0.715041\tvalid_1's auc: 0.685285\n",
      "[950]\ttraining's auc: 0.716974\tvalid_1's auc: 0.685842\n",
      "[1000]\ttraining's auc: 0.718567\tvalid_1's auc: 0.686107\n",
      "[1050]\ttraining's auc: 0.720352\tvalid_1's auc: 0.686567\n",
      "[1100]\ttraining's auc: 0.722033\tvalid_1's auc: 0.686744\n",
      "[1150]\ttraining's auc: 0.723877\tvalid_1's auc: 0.687322\n",
      "[1200]\ttraining's auc: 0.72552\tvalid_1's auc: 0.687582\n",
      "[1250]\ttraining's auc: 0.727156\tvalid_1's auc: 0.687902\n",
      "[1300]\ttraining's auc: 0.728728\tvalid_1's auc: 0.687987\n",
      "[1350]\ttraining's auc: 0.730253\tvalid_1's auc: 0.688471\n",
      "[1400]\ttraining's auc: 0.731714\tvalid_1's auc: 0.688782\n",
      "[1450]\ttraining's auc: 0.733249\tvalid_1's auc: 0.689136\n",
      "[1500]\ttraining's auc: 0.734808\tvalid_1's auc: 0.689476\n",
      "[1550]\ttraining's auc: 0.736278\tvalid_1's auc: 0.689649\n",
      "[1600]\ttraining's auc: 0.737461\tvalid_1's auc: 0.689756\n",
      "[1650]\ttraining's auc: 0.73909\tvalid_1's auc: 0.690086\n",
      "[1700]\ttraining's auc: 0.74056\tvalid_1's auc: 0.690184\n",
      "[1750]\ttraining's auc: 0.741755\tvalid_1's auc: 0.690174\n",
      "[1800]\ttraining's auc: 0.742928\tvalid_1's auc: 0.69043\n",
      "[1850]\ttraining's auc: 0.744205\tvalid_1's auc: 0.690687\n",
      "[1900]\ttraining's auc: 0.745169\tvalid_1's auc: 0.690698\n",
      "[1950]\ttraining's auc: 0.746194\tvalid_1's auc: 0.690899\n",
      "[2000]\ttraining's auc: 0.747131\tvalid_1's auc: 0.690931\n",
      "[2050]\ttraining's auc: 0.748277\tvalid_1's auc: 0.691184\n",
      "[2100]\ttraining's auc: 0.749652\tvalid_1's auc: 0.691439\n",
      "[2150]\ttraining's auc: 0.75059\tvalid_1's auc: 0.691578\n",
      "[2200]\ttraining's auc: 0.751633\tvalid_1's auc: 0.691746\n",
      "[2250]\ttraining's auc: 0.752888\tvalid_1's auc: 0.692074\n",
      "[2300]\ttraining's auc: 0.753873\tvalid_1's auc: 0.692464\n",
      "[2350]\ttraining's auc: 0.754882\tvalid_1's auc: 0.692263\n",
      "[2400]\ttraining's auc: 0.756256\tvalid_1's auc: 0.692328\n",
      "[2450]\ttraining's auc: 0.757157\tvalid_1's auc: 0.692491\n",
      "[2500]\ttraining's auc: 0.758276\tvalid_1's auc: 0.69244\n",
      "[2550]\ttraining's auc: 0.759174\tvalid_1's auc: 0.692432\n",
      "[2600]\ttraining's auc: 0.760197\tvalid_1's auc: 0.692566\n",
      "[2650]\ttraining's auc: 0.761258\tvalid_1's auc: 0.692819\n",
      "[2700]\ttraining's auc: 0.762121\tvalid_1's auc: 0.692842\n",
      "[2750]\ttraining's auc: 0.762878\tvalid_1's auc: 0.693036\n",
      "[2800]\ttraining's auc: 0.763734\tvalid_1's auc: 0.693049\n",
      "[2850]\ttraining's auc: 0.764669\tvalid_1's auc: 0.693063\n",
      "[2900]\ttraining's auc: 0.765496\tvalid_1's auc: 0.693062\n",
      "[2950]\ttraining's auc: 0.766613\tvalid_1's auc: 0.693074\n",
      "[3000]\ttraining's auc: 0.767584\tvalid_1's auc: 0.693235\n",
      "[3050]\ttraining's auc: 0.768535\tvalid_1's auc: 0.693462\n",
      "[3100]\ttraining's auc: 0.769439\tvalid_1's auc: 0.693456\n",
      "[3150]\ttraining's auc: 0.770145\tvalid_1's auc: 0.693661\n",
      "[3200]\ttraining's auc: 0.771042\tvalid_1's auc: 0.69365\n",
      "[3250]\ttraining's auc: 0.772015\tvalid_1's auc: 0.693662\n",
      "[3300]\ttraining's auc: 0.772829\tvalid_1's auc: 0.693578\n",
      "Early stopping, best iteration is:\n",
      "[3145]\ttraining's auc: 0.770009\tvalid_1's auc: 0.693703\n",
      "Fold  2 AUC : 0.693704\n",
      "Train Index: [     0      1      2 ... 296234 296235 296236] ,Val Index: [    19     26     31 ... 296197 296229 296230]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.672857\tvalid_1's auc: 0.653142\n",
      "[100]\ttraining's auc: 0.676625\tvalid_1's auc: 0.656691\n",
      "[150]\ttraining's auc: 0.679223\tvalid_1's auc: 0.657926\n",
      "[200]\ttraining's auc: 0.681817\tvalid_1's auc: 0.659357\n",
      "[250]\ttraining's auc: 0.684522\tvalid_1's auc: 0.660127\n",
      "[300]\ttraining's auc: 0.686483\tvalid_1's auc: 0.660907\n",
      "[350]\ttraining's auc: 0.689325\tvalid_1's auc: 0.662244\n",
      "[400]\ttraining's auc: 0.692188\tvalid_1's auc: 0.663796\n",
      "[450]\ttraining's auc: 0.69478\tvalid_1's auc: 0.664889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's auc: 0.697404\tvalid_1's auc: 0.666129\n",
      "[550]\ttraining's auc: 0.699721\tvalid_1's auc: 0.667002\n",
      "[600]\ttraining's auc: 0.70237\tvalid_1's auc: 0.668112\n",
      "[650]\ttraining's auc: 0.704858\tvalid_1's auc: 0.668816\n",
      "[700]\ttraining's auc: 0.707518\tvalid_1's auc: 0.669575\n",
      "[750]\ttraining's auc: 0.709907\tvalid_1's auc: 0.670494\n",
      "[800]\ttraining's auc: 0.711589\tvalid_1's auc: 0.670793\n",
      "[850]\ttraining's auc: 0.713914\tvalid_1's auc: 0.671644\n",
      "[900]\ttraining's auc: 0.716111\tvalid_1's auc: 0.672112\n",
      "[950]\ttraining's auc: 0.717748\tvalid_1's auc: 0.672484\n",
      "[1000]\ttraining's auc: 0.719386\tvalid_1's auc: 0.672733\n",
      "[1050]\ttraining's auc: 0.721478\tvalid_1's auc: 0.673088\n",
      "[1100]\ttraining's auc: 0.723362\tvalid_1's auc: 0.673635\n",
      "[1150]\ttraining's auc: 0.725295\tvalid_1's auc: 0.674157\n",
      "[1200]\ttraining's auc: 0.727001\tvalid_1's auc: 0.673952\n",
      "[1250]\ttraining's auc: 0.728537\tvalid_1's auc: 0.67412\n",
      "[1300]\ttraining's auc: 0.730095\tvalid_1's auc: 0.674198\n",
      "[1350]\ttraining's auc: 0.731568\tvalid_1's auc: 0.674308\n",
      "[1400]\ttraining's auc: 0.733127\tvalid_1's auc: 0.674602\n",
      "[1450]\ttraining's auc: 0.734536\tvalid_1's auc: 0.674889\n",
      "[1500]\ttraining's auc: 0.735869\tvalid_1's auc: 0.67542\n",
      "[1550]\ttraining's auc: 0.737474\tvalid_1's auc: 0.675649\n",
      "[1600]\ttraining's auc: 0.738744\tvalid_1's auc: 0.67581\n",
      "[1650]\ttraining's auc: 0.740435\tvalid_1's auc: 0.676261\n",
      "[1700]\ttraining's auc: 0.741748\tvalid_1's auc: 0.676566\n",
      "[1750]\ttraining's auc: 0.742774\tvalid_1's auc: 0.676623\n",
      "[1800]\ttraining's auc: 0.744067\tvalid_1's auc: 0.676789\n",
      "[1850]\ttraining's auc: 0.74542\tvalid_1's auc: 0.676824\n",
      "[1900]\ttraining's auc: 0.746412\tvalid_1's auc: 0.677095\n",
      "[1950]\ttraining's auc: 0.747566\tvalid_1's auc: 0.677195\n",
      "[2000]\ttraining's auc: 0.748502\tvalid_1's auc: 0.677226\n",
      "[2050]\ttraining's auc: 0.749724\tvalid_1's auc: 0.67741\n",
      "[2100]\ttraining's auc: 0.750898\tvalid_1's auc: 0.677375\n",
      "[2150]\ttraining's auc: 0.751951\tvalid_1's auc: 0.67745\n",
      "[2200]\ttraining's auc: 0.753026\tvalid_1's auc: 0.67763\n",
      "[2250]\ttraining's auc: 0.753982\tvalid_1's auc: 0.677652\n",
      "[2300]\ttraining's auc: 0.755061\tvalid_1's auc: 0.677931\n",
      "[2350]\ttraining's auc: 0.756108\tvalid_1's auc: 0.67799\n",
      "[2400]\ttraining's auc: 0.757354\tvalid_1's auc: 0.678086\n",
      "[2450]\ttraining's auc: 0.758176\tvalid_1's auc: 0.678383\n",
      "[2500]\ttraining's auc: 0.759266\tvalid_1's auc: 0.678344\n",
      "[2550]\ttraining's auc: 0.760315\tvalid_1's auc: 0.678464\n",
      "[2600]\ttraining's auc: 0.761383\tvalid_1's auc: 0.678519\n",
      "[2650]\ttraining's auc: 0.76257\tvalid_1's auc: 0.678758\n",
      "[2700]\ttraining's auc: 0.763572\tvalid_1's auc: 0.678914\n",
      "[2750]\ttraining's auc: 0.7645\tvalid_1's auc: 0.678791\n",
      "[2800]\ttraining's auc: 0.765505\tvalid_1's auc: 0.678611\n",
      "[2850]\ttraining's auc: 0.766291\tvalid_1's auc: 0.678665\n",
      "[2900]\ttraining's auc: 0.767269\tvalid_1's auc: 0.678762\n",
      "Early stopping, best iteration is:\n",
      "[2706]\ttraining's auc: 0.763686\tvalid_1's auc: 0.678951\n",
      "Fold  3 AUC : 0.678958\n",
      "Train Index: [     0      1      2 ... 296234 296235 296236] ,Val Index: [     5     10     11 ... 296208 296221 296227]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.671305\tvalid_1's auc: 0.663732\n",
      "[100]\ttraining's auc: 0.674478\tvalid_1's auc: 0.666401\n",
      "[150]\ttraining's auc: 0.677606\tvalid_1's auc: 0.668703\n",
      "[200]\ttraining's auc: 0.680423\tvalid_1's auc: 0.670164\n",
      "[250]\ttraining's auc: 0.683168\tvalid_1's auc: 0.671612\n",
      "[300]\ttraining's auc: 0.685552\tvalid_1's auc: 0.672461\n",
      "[350]\ttraining's auc: 0.688246\tvalid_1's auc: 0.673783\n",
      "[400]\ttraining's auc: 0.69129\tvalid_1's auc: 0.675373\n",
      "[450]\ttraining's auc: 0.693969\tvalid_1's auc: 0.676611\n",
      "[500]\ttraining's auc: 0.696326\tvalid_1's auc: 0.677426\n",
      "[550]\ttraining's auc: 0.698461\tvalid_1's auc: 0.677953\n",
      "[600]\ttraining's auc: 0.701175\tvalid_1's auc: 0.678947\n",
      "[650]\ttraining's auc: 0.70385\tvalid_1's auc: 0.680189\n",
      "[700]\ttraining's auc: 0.706568\tvalid_1's auc: 0.681193\n",
      "[750]\ttraining's auc: 0.708921\tvalid_1's auc: 0.681894\n",
      "[800]\ttraining's auc: 0.710584\tvalid_1's auc: 0.682465\n",
      "[850]\ttraining's auc: 0.712667\tvalid_1's auc: 0.682888\n",
      "[900]\ttraining's auc: 0.715042\tvalid_1's auc: 0.683687\n",
      "[950]\ttraining's auc: 0.716885\tvalid_1's auc: 0.684311\n",
      "[1000]\ttraining's auc: 0.718738\tvalid_1's auc: 0.684473\n",
      "[1050]\ttraining's auc: 0.720749\tvalid_1's auc: 0.68511\n",
      "[1100]\ttraining's auc: 0.72246\tvalid_1's auc: 0.685454\n",
      "[1150]\ttraining's auc: 0.724208\tvalid_1's auc: 0.685726\n",
      "[1200]\ttraining's auc: 0.72596\tvalid_1's auc: 0.686286\n",
      "[1250]\ttraining's auc: 0.727402\tvalid_1's auc: 0.686388\n",
      "[1300]\ttraining's auc: 0.728891\tvalid_1's auc: 0.686722\n",
      "[1350]\ttraining's auc: 0.730429\tvalid_1's auc: 0.687125\n",
      "[1400]\ttraining's auc: 0.731894\tvalid_1's auc: 0.687407\n",
      "[1450]\ttraining's auc: 0.733442\tvalid_1's auc: 0.687641\n",
      "[1500]\ttraining's auc: 0.734705\tvalid_1's auc: 0.688134\n",
      "[1550]\ttraining's auc: 0.736384\tvalid_1's auc: 0.688724\n",
      "[1600]\ttraining's auc: 0.73774\tvalid_1's auc: 0.688761\n",
      "[1650]\ttraining's auc: 0.739407\tvalid_1's auc: 0.688808\n",
      "[1700]\ttraining's auc: 0.740973\tvalid_1's auc: 0.68909\n",
      "[1750]\ttraining's auc: 0.742357\tvalid_1's auc: 0.689412\n",
      "[1800]\ttraining's auc: 0.743614\tvalid_1's auc: 0.689677\n",
      "[1850]\ttraining's auc: 0.744866\tvalid_1's auc: 0.690002\n",
      "[1900]\ttraining's auc: 0.74615\tvalid_1's auc: 0.690193\n",
      "[1950]\ttraining's auc: 0.747296\tvalid_1's auc: 0.690087\n",
      "[2000]\ttraining's auc: 0.74834\tvalid_1's auc: 0.690179\n",
      "[2050]\ttraining's auc: 0.749373\tvalid_1's auc: 0.690131\n",
      "[2100]\ttraining's auc: 0.750551\tvalid_1's auc: 0.690352\n",
      "[2150]\ttraining's auc: 0.751633\tvalid_1's auc: 0.690577\n",
      "[2200]\ttraining's auc: 0.752796\tvalid_1's auc: 0.690581\n",
      "[2250]\ttraining's auc: 0.753916\tvalid_1's auc: 0.690836\n",
      "[2300]\ttraining's auc: 0.754901\tvalid_1's auc: 0.690925\n",
      "[2350]\ttraining's auc: 0.756047\tvalid_1's auc: 0.691115\n",
      "[2400]\ttraining's auc: 0.757197\tvalid_1's auc: 0.691487\n",
      "[2450]\ttraining's auc: 0.758067\tvalid_1's auc: 0.691646\n",
      "[2500]\ttraining's auc: 0.7591\tvalid_1's auc: 0.691741\n",
      "[2550]\ttraining's auc: 0.759954\tvalid_1's auc: 0.691761\n",
      "[2600]\ttraining's auc: 0.760949\tvalid_1's auc: 0.69185\n",
      "[2650]\ttraining's auc: 0.761996\tvalid_1's auc: 0.691852\n",
      "[2700]\ttraining's auc: 0.762935\tvalid_1's auc: 0.691792\n",
      "[2750]\ttraining's auc: 0.763913\tvalid_1's auc: 0.691922\n",
      "Early stopping, best iteration is:\n",
      "[2574]\ttraining's auc: 0.760398\tvalid_1's auc: 0.691977\n",
      "Fold  4 AUC : 0.691990\n",
      "Train Index: [     0      1      3 ... 296234 296235 296236] ,Val Index: [     2      9     52 ... 296225 296228 296232]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.670786\tvalid_1's auc: 0.665293\n",
      "[100]\ttraining's auc: 0.674306\tvalid_1's auc: 0.669005\n",
      "[150]\ttraining's auc: 0.677631\tvalid_1's auc: 0.670348\n",
      "[200]\ttraining's auc: 0.680451\tvalid_1's auc: 0.671593\n",
      "[250]\ttraining's auc: 0.683226\tvalid_1's auc: 0.672453\n",
      "[300]\ttraining's auc: 0.685455\tvalid_1's auc: 0.673738\n",
      "[350]\ttraining's auc: 0.688368\tvalid_1's auc: 0.675357\n",
      "[400]\ttraining's auc: 0.69135\tvalid_1's auc: 0.676328\n",
      "[450]\ttraining's auc: 0.694091\tvalid_1's auc: 0.677648\n",
      "[500]\ttraining's auc: 0.696627\tvalid_1's auc: 0.678666\n",
      "[550]\ttraining's auc: 0.698785\tvalid_1's auc: 0.679416\n",
      "[600]\ttraining's auc: 0.701344\tvalid_1's auc: 0.680216\n",
      "[650]\ttraining's auc: 0.703782\tvalid_1's auc: 0.681131\n",
      "[700]\ttraining's auc: 0.706239\tvalid_1's auc: 0.682147\n",
      "[750]\ttraining's auc: 0.708625\tvalid_1's auc: 0.683057\n",
      "[800]\ttraining's auc: 0.710347\tvalid_1's auc: 0.683505\n",
      "[850]\ttraining's auc: 0.712752\tvalid_1's auc: 0.683901\n",
      "[900]\ttraining's auc: 0.715021\tvalid_1's auc: 0.684805\n",
      "[950]\ttraining's auc: 0.716894\tvalid_1's auc: 0.685525\n",
      "[1000]\ttraining's auc: 0.718785\tvalid_1's auc: 0.686143\n",
      "[1050]\ttraining's auc: 0.720789\tvalid_1's auc: 0.686817\n",
      "[1100]\ttraining's auc: 0.722409\tvalid_1's auc: 0.687019\n",
      "[1150]\ttraining's auc: 0.724008\tvalid_1's auc: 0.687463\n",
      "[1200]\ttraining's auc: 0.725742\tvalid_1's auc: 0.687808\n",
      "[1250]\ttraining's auc: 0.727276\tvalid_1's auc: 0.688137\n",
      "[1300]\ttraining's auc: 0.728669\tvalid_1's auc: 0.688302\n",
      "[1350]\ttraining's auc: 0.730289\tvalid_1's auc: 0.688556\n",
      "[1400]\ttraining's auc: 0.731829\tvalid_1's auc: 0.688744\n",
      "[1450]\ttraining's auc: 0.733367\tvalid_1's auc: 0.689146\n",
      "[1500]\ttraining's auc: 0.734824\tvalid_1's auc: 0.689398\n",
      "[1550]\ttraining's auc: 0.736327\tvalid_1's auc: 0.689605\n",
      "[1600]\ttraining's auc: 0.73762\tvalid_1's auc: 0.68953\n",
      "[1650]\ttraining's auc: 0.739123\tvalid_1's auc: 0.689576\n",
      "[1700]\ttraining's auc: 0.740536\tvalid_1's auc: 0.689895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1750]\ttraining's auc: 0.74173\tvalid_1's auc: 0.689997\n",
      "[1800]\ttraining's auc: 0.743086\tvalid_1's auc: 0.690161\n",
      "[1850]\ttraining's auc: 0.744324\tvalid_1's auc: 0.690122\n",
      "[1900]\ttraining's auc: 0.745356\tvalid_1's auc: 0.690342\n",
      "[1950]\ttraining's auc: 0.746409\tvalid_1's auc: 0.69049\n",
      "[2000]\ttraining's auc: 0.747558\tvalid_1's auc: 0.690743\n",
      "[2050]\ttraining's auc: 0.748774\tvalid_1's auc: 0.690953\n",
      "[2100]\ttraining's auc: 0.750053\tvalid_1's auc: 0.691144\n",
      "[2150]\ttraining's auc: 0.751125\tvalid_1's auc: 0.691084\n",
      "[2200]\ttraining's auc: 0.752107\tvalid_1's auc: 0.690986\n",
      "[2250]\ttraining's auc: 0.753407\tvalid_1's auc: 0.691013\n",
      "[2300]\ttraining's auc: 0.754337\tvalid_1's auc: 0.691304\n",
      "[2350]\ttraining's auc: 0.755282\tvalid_1's auc: 0.691244\n",
      "[2400]\ttraining's auc: 0.756502\tvalid_1's auc: 0.691255\n",
      "[2450]\ttraining's auc: 0.757518\tvalid_1's auc: 0.691235\n",
      "[2500]\ttraining's auc: 0.758566\tvalid_1's auc: 0.691178\n",
      "Early stopping, best iteration is:\n",
      "[2318]\ttraining's auc: 0.754595\tvalid_1's auc: 0.691353\n",
      "Fold  5 AUC : 0.691361\n",
      "Train Index: [     0      1      2 ... 296233 296234 296235] ,Val Index: [    12     14     32 ... 296226 296231 296236]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.670783\tvalid_1's auc: 0.668069\n",
      "[100]\ttraining's auc: 0.674712\tvalid_1's auc: 0.671326\n",
      "[150]\ttraining's auc: 0.677698\tvalid_1's auc: 0.672493\n",
      "[200]\ttraining's auc: 0.68078\tvalid_1's auc: 0.674238\n",
      "[250]\ttraining's auc: 0.683568\tvalid_1's auc: 0.675305\n",
      "[300]\ttraining's auc: 0.685503\tvalid_1's auc: 0.676434\n",
      "[350]\ttraining's auc: 0.688506\tvalid_1's auc: 0.677621\n",
      "[400]\ttraining's auc: 0.691502\tvalid_1's auc: 0.678843\n",
      "[450]\ttraining's auc: 0.694153\tvalid_1's auc: 0.679829\n",
      "[500]\ttraining's auc: 0.696613\tvalid_1's auc: 0.681093\n",
      "[550]\ttraining's auc: 0.69852\tvalid_1's auc: 0.681792\n",
      "[600]\ttraining's auc: 0.700934\tvalid_1's auc: 0.682785\n",
      "[650]\ttraining's auc: 0.703473\tvalid_1's auc: 0.683553\n",
      "[700]\ttraining's auc: 0.7063\tvalid_1's auc: 0.684401\n",
      "[750]\ttraining's auc: 0.708599\tvalid_1's auc: 0.684991\n",
      "[800]\ttraining's auc: 0.710421\tvalid_1's auc: 0.685362\n",
      "[850]\ttraining's auc: 0.712546\tvalid_1's auc: 0.685649\n",
      "[900]\ttraining's auc: 0.714922\tvalid_1's auc: 0.686166\n",
      "[950]\ttraining's auc: 0.716783\tvalid_1's auc: 0.686536\n",
      "[1000]\ttraining's auc: 0.718342\tvalid_1's auc: 0.686637\n",
      "[1050]\ttraining's auc: 0.720357\tvalid_1's auc: 0.687084\n",
      "[1100]\ttraining's auc: 0.722273\tvalid_1's auc: 0.687416\n",
      "[1150]\ttraining's auc: 0.724045\tvalid_1's auc: 0.687583\n",
      "[1200]\ttraining's auc: 0.725654\tvalid_1's auc: 0.687869\n",
      "[1250]\ttraining's auc: 0.727324\tvalid_1's auc: 0.688101\n",
      "[1300]\ttraining's auc: 0.728809\tvalid_1's auc: 0.688161\n",
      "[1350]\ttraining's auc: 0.730264\tvalid_1's auc: 0.688472\n",
      "[1400]\ttraining's auc: 0.731811\tvalid_1's auc: 0.688743\n",
      "[1450]\ttraining's auc: 0.733244\tvalid_1's auc: 0.689138\n",
      "[1500]\ttraining's auc: 0.734718\tvalid_1's auc: 0.68934\n",
      "[1550]\ttraining's auc: 0.736207\tvalid_1's auc: 0.689663\n",
      "[1600]\ttraining's auc: 0.73758\tvalid_1's auc: 0.68979\n",
      "[1650]\ttraining's auc: 0.739245\tvalid_1's auc: 0.689886\n",
      "[1700]\ttraining's auc: 0.740866\tvalid_1's auc: 0.690118\n",
      "[1750]\ttraining's auc: 0.7422\tvalid_1's auc: 0.690112\n",
      "[1800]\ttraining's auc: 0.743351\tvalid_1's auc: 0.690054\n",
      "[1850]\ttraining's auc: 0.744628\tvalid_1's auc: 0.690407\n",
      "[1900]\ttraining's auc: 0.745618\tvalid_1's auc: 0.690606\n",
      "[1950]\ttraining's auc: 0.746621\tvalid_1's auc: 0.690748\n",
      "[2000]\ttraining's auc: 0.747729\tvalid_1's auc: 0.690707\n",
      "[2050]\ttraining's auc: 0.748841\tvalid_1's auc: 0.690713\n",
      "[2100]\ttraining's auc: 0.750149\tvalid_1's auc: 0.690699\n",
      "[2150]\ttraining's auc: 0.751314\tvalid_1's auc: 0.690817\n",
      "[2200]\ttraining's auc: 0.752324\tvalid_1's auc: 0.690693\n",
      "[2250]\ttraining's auc: 0.753558\tvalid_1's auc: 0.690672\n",
      "[2300]\ttraining's auc: 0.75456\tvalid_1's auc: 0.690821\n",
      "[2350]\ttraining's auc: 0.755665\tvalid_1's auc: 0.690841\n",
      "[2400]\ttraining's auc: 0.75668\tvalid_1's auc: 0.690714\n",
      "[2450]\ttraining's auc: 0.75757\tvalid_1's auc: 0.690729\n",
      "[2500]\ttraining's auc: 0.758722\tvalid_1's auc: 0.690886\n",
      "[2550]\ttraining's auc: 0.759663\tvalid_1's auc: 0.690802\n",
      "[2600]\ttraining's auc: 0.760672\tvalid_1's auc: 0.691132\n",
      "[2650]\ttraining's auc: 0.761648\tvalid_1's auc: 0.6909\n",
      "[2700]\ttraining's auc: 0.762598\tvalid_1's auc: 0.690946\n",
      "[2750]\ttraining's auc: 0.763444\tvalid_1's auc: 0.691104\n",
      "[2800]\ttraining's auc: 0.764478\tvalid_1's auc: 0.691168\n",
      "[2850]\ttraining's auc: 0.765423\tvalid_1's auc: 0.691141\n",
      "[2900]\ttraining's auc: 0.766297\tvalid_1's auc: 0.691199\n",
      "[2950]\ttraining's auc: 0.767394\tvalid_1's auc: 0.691008\n",
      "[3000]\ttraining's auc: 0.768444\tvalid_1's auc: 0.69099\n",
      "[3050]\ttraining's auc: 0.76943\tvalid_1's auc: 0.691021\n",
      "Early stopping, best iteration is:\n",
      "[2875]\ttraining's auc: 0.765902\tvalid_1's auc: 0.691244\n",
      "Fold  6 AUC : 0.691233\n",
      "Train Index: [     0      1      2 ... 296234 296235 296236] ,Val Index: [    13     21     22 ... 296205 296209 296233]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.670585\tvalid_1's auc: 0.665392\n",
      "[100]\ttraining's auc: 0.674465\tvalid_1's auc: 0.668081\n",
      "[150]\ttraining's auc: 0.67698\tvalid_1's auc: 0.669129\n",
      "[200]\ttraining's auc: 0.680305\tvalid_1's auc: 0.670649\n",
      "[250]\ttraining's auc: 0.683107\tvalid_1's auc: 0.671879\n",
      "[300]\ttraining's auc: 0.685524\tvalid_1's auc: 0.672937\n",
      "[350]\ttraining's auc: 0.688495\tvalid_1's auc: 0.674123\n",
      "[400]\ttraining's auc: 0.69109\tvalid_1's auc: 0.674807\n",
      "[450]\ttraining's auc: 0.694189\tvalid_1's auc: 0.676293\n",
      "[500]\ttraining's auc: 0.696577\tvalid_1's auc: 0.67726\n",
      "[550]\ttraining's auc: 0.698798\tvalid_1's auc: 0.677883\n",
      "[600]\ttraining's auc: 0.701496\tvalid_1's auc: 0.678861\n",
      "[650]\ttraining's auc: 0.703786\tvalid_1's auc: 0.6796\n",
      "[700]\ttraining's auc: 0.70635\tvalid_1's auc: 0.680541\n",
      "[750]\ttraining's auc: 0.708539\tvalid_1's auc: 0.681101\n",
      "[800]\ttraining's auc: 0.710179\tvalid_1's auc: 0.681472\n",
      "[850]\ttraining's auc: 0.712604\tvalid_1's auc: 0.682116\n",
      "[900]\ttraining's auc: 0.714874\tvalid_1's auc: 0.682783\n",
      "[950]\ttraining's auc: 0.71667\tvalid_1's auc: 0.683103\n",
      "[1000]\ttraining's auc: 0.718198\tvalid_1's auc: 0.683513\n",
      "[1050]\ttraining's auc: 0.720084\tvalid_1's auc: 0.68392\n",
      "[1100]\ttraining's auc: 0.721772\tvalid_1's auc: 0.68417\n",
      "[1150]\ttraining's auc: 0.723568\tvalid_1's auc: 0.684502\n",
      "[1200]\ttraining's auc: 0.725246\tvalid_1's auc: 0.684803\n",
      "[1250]\ttraining's auc: 0.726867\tvalid_1's auc: 0.684935\n",
      "[1300]\ttraining's auc: 0.728422\tvalid_1's auc: 0.68522\n",
      "[1350]\ttraining's auc: 0.729882\tvalid_1's auc: 0.685475\n",
      "[1400]\ttraining's auc: 0.731255\tvalid_1's auc: 0.685762\n",
      "[1450]\ttraining's auc: 0.732667\tvalid_1's auc: 0.686059\n",
      "[1500]\ttraining's auc: 0.734187\tvalid_1's auc: 0.686349\n",
      "[1550]\ttraining's auc: 0.735722\tvalid_1's auc: 0.686874\n",
      "[1600]\ttraining's auc: 0.736986\tvalid_1's auc: 0.686902\n",
      "[1650]\ttraining's auc: 0.73859\tvalid_1's auc: 0.687052\n",
      "[1700]\ttraining's auc: 0.739955\tvalid_1's auc: 0.687232\n",
      "[1750]\ttraining's auc: 0.74133\tvalid_1's auc: 0.68743\n",
      "[1800]\ttraining's auc: 0.742655\tvalid_1's auc: 0.687305\n",
      "[1850]\ttraining's auc: 0.744112\tvalid_1's auc: 0.687678\n",
      "[1900]\ttraining's auc: 0.745142\tvalid_1's auc: 0.687789\n",
      "[1950]\ttraining's auc: 0.746219\tvalid_1's auc: 0.687843\n",
      "[2000]\ttraining's auc: 0.7473\tvalid_1's auc: 0.687867\n",
      "[2050]\ttraining's auc: 0.748558\tvalid_1's auc: 0.687902\n",
      "[2100]\ttraining's auc: 0.749711\tvalid_1's auc: 0.687825\n",
      "[2150]\ttraining's auc: 0.75069\tvalid_1's auc: 0.687925\n",
      "[2200]\ttraining's auc: 0.751858\tvalid_1's auc: 0.688108\n",
      "[2250]\ttraining's auc: 0.752967\tvalid_1's auc: 0.68826\n",
      "[2300]\ttraining's auc: 0.753988\tvalid_1's auc: 0.688405\n",
      "[2350]\ttraining's auc: 0.754955\tvalid_1's auc: 0.688535\n",
      "[2400]\ttraining's auc: 0.756074\tvalid_1's auc: 0.688616\n",
      "[2450]\ttraining's auc: 0.757014\tvalid_1's auc: 0.688542\n",
      "[2500]\ttraining's auc: 0.757978\tvalid_1's auc: 0.688464\n",
      "[2550]\ttraining's auc: 0.759017\tvalid_1's auc: 0.688725\n",
      "[2600]\ttraining's auc: 0.760048\tvalid_1's auc: 0.688737\n",
      "[2650]\ttraining's auc: 0.761313\tvalid_1's auc: 0.688789\n",
      "[2700]\ttraining's auc: 0.762197\tvalid_1's auc: 0.688864\n",
      "[2750]\ttraining's auc: 0.763107\tvalid_1's auc: 0.68883\n",
      "[2800]\ttraining's auc: 0.764092\tvalid_1's auc: 0.688881\n",
      "[2850]\ttraining's auc: 0.765217\tvalid_1's auc: 0.688752\n",
      "[2900]\ttraining's auc: 0.766172\tvalid_1's auc: 0.688683\n",
      "[2950]\ttraining's auc: 0.767209\tvalid_1's auc: 0.688813\n",
      "Early stopping, best iteration is:\n",
      "[2769]\ttraining's auc: 0.763389\tvalid_1's auc: 0.688967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  7 AUC : 0.688970\n",
      "Train Index: [     0      2      3 ... 296234 296235 296236] ,Val Index: [     1     16     25 ... 296155 296206 296216]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.671848\tvalid_1's auc: 0.664193\n",
      "[100]\ttraining's auc: 0.675645\tvalid_1's auc: 0.667083\n",
      "[150]\ttraining's auc: 0.678234\tvalid_1's auc: 0.667967\n",
      "[200]\ttraining's auc: 0.680812\tvalid_1's auc: 0.669467\n",
      "[250]\ttraining's auc: 0.683658\tvalid_1's auc: 0.670429\n",
      "[300]\ttraining's auc: 0.685741\tvalid_1's auc: 0.671127\n",
      "[350]\ttraining's auc: 0.688414\tvalid_1's auc: 0.67237\n",
      "[400]\ttraining's auc: 0.690987\tvalid_1's auc: 0.673486\n",
      "[450]\ttraining's auc: 0.693651\tvalid_1's auc: 0.674469\n",
      "[500]\ttraining's auc: 0.695872\tvalid_1's auc: 0.675528\n",
      "[550]\ttraining's auc: 0.698459\tvalid_1's auc: 0.676592\n",
      "[600]\ttraining's auc: 0.701078\tvalid_1's auc: 0.677691\n",
      "[650]\ttraining's auc: 0.703464\tvalid_1's auc: 0.678573\n",
      "[700]\ttraining's auc: 0.706002\tvalid_1's auc: 0.679713\n",
      "[750]\ttraining's auc: 0.708349\tvalid_1's auc: 0.680404\n",
      "[800]\ttraining's auc: 0.709862\tvalid_1's auc: 0.680866\n",
      "[850]\ttraining's auc: 0.712122\tvalid_1's auc: 0.681645\n",
      "[900]\ttraining's auc: 0.714455\tvalid_1's auc: 0.682279\n",
      "[950]\ttraining's auc: 0.716264\tvalid_1's auc: 0.682844\n",
      "[1000]\ttraining's auc: 0.717921\tvalid_1's auc: 0.683404\n",
      "[1050]\ttraining's auc: 0.719947\tvalid_1's auc: 0.68377\n",
      "[1100]\ttraining's auc: 0.72191\tvalid_1's auc: 0.684234\n",
      "[1150]\ttraining's auc: 0.723801\tvalid_1's auc: 0.684679\n",
      "[1200]\ttraining's auc: 0.72568\tvalid_1's auc: 0.685008\n",
      "[1250]\ttraining's auc: 0.7273\tvalid_1's auc: 0.685221\n",
      "[1300]\ttraining's auc: 0.728672\tvalid_1's auc: 0.685264\n",
      "[1350]\ttraining's auc: 0.730198\tvalid_1's auc: 0.68581\n",
      "[1400]\ttraining's auc: 0.731815\tvalid_1's auc: 0.686043\n",
      "[1450]\ttraining's auc: 0.733267\tvalid_1's auc: 0.686513\n",
      "[1500]\ttraining's auc: 0.734582\tvalid_1's auc: 0.686757\n",
      "[1550]\ttraining's auc: 0.73638\tvalid_1's auc: 0.686994\n",
      "[1600]\ttraining's auc: 0.737695\tvalid_1's auc: 0.687301\n",
      "[1650]\ttraining's auc: 0.738907\tvalid_1's auc: 0.68775\n",
      "[1700]\ttraining's auc: 0.740283\tvalid_1's auc: 0.68773\n",
      "[1750]\ttraining's auc: 0.741635\tvalid_1's auc: 0.68821\n",
      "[1800]\ttraining's auc: 0.742913\tvalid_1's auc: 0.68833\n",
      "[1850]\ttraining's auc: 0.744091\tvalid_1's auc: 0.688591\n",
      "[1900]\ttraining's auc: 0.745227\tvalid_1's auc: 0.688787\n",
      "[1950]\ttraining's auc: 0.746421\tvalid_1's auc: 0.688928\n",
      "[2000]\ttraining's auc: 0.747474\tvalid_1's auc: 0.689087\n",
      "[2050]\ttraining's auc: 0.748652\tvalid_1's auc: 0.689363\n",
      "[2100]\ttraining's auc: 0.749702\tvalid_1's auc: 0.689683\n",
      "[2150]\ttraining's auc: 0.750844\tvalid_1's auc: 0.689858\n",
      "[2200]\ttraining's auc: 0.752004\tvalid_1's auc: 0.689954\n",
      "[2250]\ttraining's auc: 0.75324\tvalid_1's auc: 0.690093\n",
      "[2300]\ttraining's auc: 0.75425\tvalid_1's auc: 0.69035\n",
      "[2350]\ttraining's auc: 0.755176\tvalid_1's auc: 0.690477\n",
      "[2400]\ttraining's auc: 0.756538\tvalid_1's auc: 0.690617\n",
      "[2450]\ttraining's auc: 0.757369\tvalid_1's auc: 0.691078\n",
      "[2500]\ttraining's auc: 0.758587\tvalid_1's auc: 0.691208\n",
      "[2550]\ttraining's auc: 0.759482\tvalid_1's auc: 0.691348\n",
      "[2600]\ttraining's auc: 0.760418\tvalid_1's auc: 0.691453\n",
      "[2650]\ttraining's auc: 0.761477\tvalid_1's auc: 0.69135\n",
      "[2700]\ttraining's auc: 0.762613\tvalid_1's auc: 0.691638\n",
      "[2750]\ttraining's auc: 0.763556\tvalid_1's auc: 0.691586\n",
      "[2800]\ttraining's auc: 0.764493\tvalid_1's auc: 0.691621\n",
      "[2850]\ttraining's auc: 0.765228\tvalid_1's auc: 0.691689\n",
      "[2900]\ttraining's auc: 0.766186\tvalid_1's auc: 0.691602\n",
      "[2950]\ttraining's auc: 0.767254\tvalid_1's auc: 0.691634\n",
      "[3000]\ttraining's auc: 0.76833\tvalid_1's auc: 0.691929\n",
      "[3050]\ttraining's auc: 0.769179\tvalid_1's auc: 0.692155\n",
      "[3100]\ttraining's auc: 0.770221\tvalid_1's auc: 0.692319\n",
      "[3150]\ttraining's auc: 0.770949\tvalid_1's auc: 0.692627\n",
      "[3200]\ttraining's auc: 0.771852\tvalid_1's auc: 0.692894\n",
      "[3250]\ttraining's auc: 0.772916\tvalid_1's auc: 0.692977\n",
      "[3300]\ttraining's auc: 0.773794\tvalid_1's auc: 0.693184\n",
      "[3350]\ttraining's auc: 0.774738\tvalid_1's auc: 0.693331\n",
      "[3400]\ttraining's auc: 0.775517\tvalid_1's auc: 0.693357\n",
      "[3450]\ttraining's auc: 0.776287\tvalid_1's auc: 0.693506\n",
      "[3500]\ttraining's auc: 0.776961\tvalid_1's auc: 0.693483\n",
      "[3550]\ttraining's auc: 0.777812\tvalid_1's auc: 0.693556\n",
      "[3600]\ttraining's auc: 0.778425\tvalid_1's auc: 0.693593\n",
      "[3650]\ttraining's auc: 0.779207\tvalid_1's auc: 0.693605\n",
      "[3700]\ttraining's auc: 0.780104\tvalid_1's auc: 0.693769\n",
      "[3750]\ttraining's auc: 0.780946\tvalid_1's auc: 0.69377\n",
      "[3800]\ttraining's auc: 0.781897\tvalid_1's auc: 0.693807\n",
      "[3850]\ttraining's auc: 0.782525\tvalid_1's auc: 0.693835\n",
      "[3900]\ttraining's auc: 0.783324\tvalid_1's auc: 0.693872\n",
      "[3950]\ttraining's auc: 0.784076\tvalid_1's auc: 0.693889\n",
      "[4000]\ttraining's auc: 0.784638\tvalid_1's auc: 0.693891\n",
      "[4050]\ttraining's auc: 0.785399\tvalid_1's auc: 0.693982\n",
      "[4100]\ttraining's auc: 0.786236\tvalid_1's auc: 0.693846\n",
      "[4150]\ttraining's auc: 0.787061\tvalid_1's auc: 0.693925\n",
      "Early stopping, best iteration is:\n",
      "[3976]\ttraining's auc: 0.784312\tvalid_1's auc: 0.694015\n",
      "Fold  8 AUC : 0.694021\n",
      "Train Index: [     0      1      2 ... 296234 296235 296236] ,Val Index: [     7      8     43 ... 296210 296212 296224]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.672104\tvalid_1's auc: 0.660173\n",
      "[100]\ttraining's auc: 0.675496\tvalid_1's auc: 0.662755\n",
      "[150]\ttraining's auc: 0.678597\tvalid_1's auc: 0.664281\n",
      "[200]\ttraining's auc: 0.681501\tvalid_1's auc: 0.665764\n",
      "[250]\ttraining's auc: 0.683999\tvalid_1's auc: 0.666622\n",
      "[300]\ttraining's auc: 0.686016\tvalid_1's auc: 0.667509\n",
      "[350]\ttraining's auc: 0.688442\tvalid_1's auc: 0.668608\n",
      "[400]\ttraining's auc: 0.691575\tvalid_1's auc: 0.670023\n",
      "[450]\ttraining's auc: 0.694274\tvalid_1's auc: 0.671031\n",
      "[500]\ttraining's auc: 0.696754\tvalid_1's auc: 0.672199\n",
      "[550]\ttraining's auc: 0.699032\tvalid_1's auc: 0.6731\n",
      "[600]\ttraining's auc: 0.701589\tvalid_1's auc: 0.673693\n",
      "[650]\ttraining's auc: 0.704163\tvalid_1's auc: 0.674382\n",
      "[700]\ttraining's auc: 0.70683\tvalid_1's auc: 0.675039\n",
      "[750]\ttraining's auc: 0.709302\tvalid_1's auc: 0.675794\n",
      "[800]\ttraining's auc: 0.711053\tvalid_1's auc: 0.676295\n",
      "[850]\ttraining's auc: 0.713271\tvalid_1's auc: 0.67686\n",
      "[900]\ttraining's auc: 0.715511\tvalid_1's auc: 0.677164\n",
      "[950]\ttraining's auc: 0.717129\tvalid_1's auc: 0.677658\n",
      "[1000]\ttraining's auc: 0.718832\tvalid_1's auc: 0.67809\n",
      "[1050]\ttraining's auc: 0.720802\tvalid_1's auc: 0.678693\n",
      "[1100]\ttraining's auc: 0.722383\tvalid_1's auc: 0.678987\n",
      "[1150]\ttraining's auc: 0.723921\tvalid_1's auc: 0.679222\n",
      "[1200]\ttraining's auc: 0.72574\tvalid_1's auc: 0.679469\n",
      "[1250]\ttraining's auc: 0.727348\tvalid_1's auc: 0.679733\n",
      "[1300]\ttraining's auc: 0.728983\tvalid_1's auc: 0.679879\n",
      "[1350]\ttraining's auc: 0.730387\tvalid_1's auc: 0.679956\n",
      "[1400]\ttraining's auc: 0.731756\tvalid_1's auc: 0.680104\n",
      "[1450]\ttraining's auc: 0.733194\tvalid_1's auc: 0.680363\n",
      "[1500]\ttraining's auc: 0.734718\tvalid_1's auc: 0.680833\n",
      "[1550]\ttraining's auc: 0.736326\tvalid_1's auc: 0.681045\n",
      "[1600]\ttraining's auc: 0.737628\tvalid_1's auc: 0.681261\n",
      "[1650]\ttraining's auc: 0.739077\tvalid_1's auc: 0.681483\n",
      "[1700]\ttraining's auc: 0.740432\tvalid_1's auc: 0.681547\n",
      "[1750]\ttraining's auc: 0.74186\tvalid_1's auc: 0.681679\n",
      "[1800]\ttraining's auc: 0.742952\tvalid_1's auc: 0.681607\n",
      "[1850]\ttraining's auc: 0.744121\tvalid_1's auc: 0.68184\n",
      "[1900]\ttraining's auc: 0.745249\tvalid_1's auc: 0.682057\n",
      "[1950]\ttraining's auc: 0.746494\tvalid_1's auc: 0.682288\n",
      "[2000]\ttraining's auc: 0.747648\tvalid_1's auc: 0.682501\n",
      "[2050]\ttraining's auc: 0.748891\tvalid_1's auc: 0.682728\n",
      "[2100]\ttraining's auc: 0.750162\tvalid_1's auc: 0.682837\n",
      "[2150]\ttraining's auc: 0.75114\tvalid_1's auc: 0.682752\n",
      "[2200]\ttraining's auc: 0.752327\tvalid_1's auc: 0.68289\n",
      "[2250]\ttraining's auc: 0.753483\tvalid_1's auc: 0.683004\n",
      "[2300]\ttraining's auc: 0.754486\tvalid_1's auc: 0.683005\n",
      "[2350]\ttraining's auc: 0.755512\tvalid_1's auc: 0.68323\n",
      "[2400]\ttraining's auc: 0.756801\tvalid_1's auc: 0.683224\n",
      "[2450]\ttraining's auc: 0.757622\tvalid_1's auc: 0.683314\n",
      "[2500]\ttraining's auc: 0.758601\tvalid_1's auc: 0.683345\n",
      "[2550]\ttraining's auc: 0.759586\tvalid_1's auc: 0.683417\n",
      "[2600]\ttraining's auc: 0.760328\tvalid_1's auc: 0.683471\n",
      "[2650]\ttraining's auc: 0.76155\tvalid_1's auc: 0.683435\n",
      "[2700]\ttraining's auc: 0.762552\tvalid_1's auc: 0.683586\n",
      "[2750]\ttraining's auc: 0.763452\tvalid_1's auc: 0.683402\n",
      "[2800]\ttraining's auc: 0.764436\tvalid_1's auc: 0.683407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2850]\ttraining's auc: 0.765432\tvalid_1's auc: 0.68349\n",
      "[2900]\ttraining's auc: 0.76635\tvalid_1's auc: 0.683636\n",
      "[2950]\ttraining's auc: 0.767492\tvalid_1's auc: 0.683906\n",
      "[3000]\ttraining's auc: 0.768635\tvalid_1's auc: 0.683713\n",
      "[3050]\ttraining's auc: 0.769401\tvalid_1's auc: 0.683635\n",
      "[3100]\ttraining's auc: 0.770378\tvalid_1's auc: 0.683805\n",
      "[3150]\ttraining's auc: 0.771192\tvalid_1's auc: 0.683836\n",
      "Early stopping, best iteration is:\n",
      "[2956]\ttraining's auc: 0.767648\tvalid_1's auc: 0.683917\n",
      "Fold  9 AUC : 0.683910\n",
      "Train Index: [     1      2      4 ... 296234 296235 296236] ,Val Index: [     0      3     17 ... 296172 296200 296204]\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttraining's auc: 0.670559\tvalid_1's auc: 0.654031\n",
      "[100]\ttraining's auc: 0.674388\tvalid_1's auc: 0.656911\n",
      "[150]\ttraining's auc: 0.677485\tvalid_1's auc: 0.658863\n",
      "[200]\ttraining's auc: 0.680136\tvalid_1's auc: 0.659953\n",
      "[250]\ttraining's auc: 0.682939\tvalid_1's auc: 0.661325\n",
      "[300]\ttraining's auc: 0.685708\tvalid_1's auc: 0.662636\n",
      "[350]\ttraining's auc: 0.688542\tvalid_1's auc: 0.664115\n",
      "[400]\ttraining's auc: 0.691215\tvalid_1's auc: 0.66551\n",
      "[450]\ttraining's auc: 0.693861\tvalid_1's auc: 0.666927\n",
      "[500]\ttraining's auc: 0.696553\tvalid_1's auc: 0.668246\n",
      "[550]\ttraining's auc: 0.6991\tvalid_1's auc: 0.669288\n",
      "[600]\ttraining's auc: 0.701823\tvalid_1's auc: 0.670616\n",
      "[650]\ttraining's auc: 0.704025\tvalid_1's auc: 0.671374\n",
      "[700]\ttraining's auc: 0.706638\tvalid_1's auc: 0.67248\n",
      "[750]\ttraining's auc: 0.708947\tvalid_1's auc: 0.673349\n",
      "[800]\ttraining's auc: 0.710765\tvalid_1's auc: 0.673857\n",
      "[850]\ttraining's auc: 0.712913\tvalid_1's auc: 0.674332\n",
      "[900]\ttraining's auc: 0.715132\tvalid_1's auc: 0.674927\n",
      "[950]\ttraining's auc: 0.716818\tvalid_1's auc: 0.675578\n",
      "[1000]\ttraining's auc: 0.718502\tvalid_1's auc: 0.675847\n",
      "[1050]\ttraining's auc: 0.720479\tvalid_1's auc: 0.676391\n",
      "[1100]\ttraining's auc: 0.722095\tvalid_1's auc: 0.676864\n",
      "[1150]\ttraining's auc: 0.72402\tvalid_1's auc: 0.677299\n",
      "[1200]\ttraining's auc: 0.725936\tvalid_1's auc: 0.677515\n",
      "[1250]\ttraining's auc: 0.727383\tvalid_1's auc: 0.677752\n",
      "[1300]\ttraining's auc: 0.729047\tvalid_1's auc: 0.67809\n",
      "[1350]\ttraining's auc: 0.730536\tvalid_1's auc: 0.678368\n",
      "[1400]\ttraining's auc: 0.732204\tvalid_1's auc: 0.678786\n",
      "[1450]\ttraining's auc: 0.733694\tvalid_1's auc: 0.679218\n",
      "[1500]\ttraining's auc: 0.735208\tvalid_1's auc: 0.679493\n",
      "[1550]\ttraining's auc: 0.736768\tvalid_1's auc: 0.679923\n",
      "[1600]\ttraining's auc: 0.738028\tvalid_1's auc: 0.680088\n",
      "[1650]\ttraining's auc: 0.739611\tvalid_1's auc: 0.680289\n",
      "[1700]\ttraining's auc: 0.741016\tvalid_1's auc: 0.680566\n",
      "[1750]\ttraining's auc: 0.742134\tvalid_1's auc: 0.680606\n",
      "[1800]\ttraining's auc: 0.743353\tvalid_1's auc: 0.681023\n",
      "[1850]\ttraining's auc: 0.744597\tvalid_1's auc: 0.681304\n",
      "[1900]\ttraining's auc: 0.745915\tvalid_1's auc: 0.681435\n",
      "[1950]\ttraining's auc: 0.746851\tvalid_1's auc: 0.681283\n",
      "[2000]\ttraining's auc: 0.74795\tvalid_1's auc: 0.681386\n",
      "[2050]\ttraining's auc: 0.749176\tvalid_1's auc: 0.681433\n",
      "[2100]\ttraining's auc: 0.750417\tvalid_1's auc: 0.68159\n",
      "[2150]\ttraining's auc: 0.751501\tvalid_1's auc: 0.681828\n",
      "[2200]\ttraining's auc: 0.752472\tvalid_1's auc: 0.681972\n",
      "[2250]\ttraining's auc: 0.753755\tvalid_1's auc: 0.682259\n",
      "[2300]\ttraining's auc: 0.754744\tvalid_1's auc: 0.68238\n",
      "[2350]\ttraining's auc: 0.755813\tvalid_1's auc: 0.682399\n",
      "[2400]\ttraining's auc: 0.75708\tvalid_1's auc: 0.682597\n",
      "[2450]\ttraining's auc: 0.757907\tvalid_1's auc: 0.682615\n",
      "[2500]\ttraining's auc: 0.758873\tvalid_1's auc: 0.682698\n",
      "[2550]\ttraining's auc: 0.759645\tvalid_1's auc: 0.682857\n",
      "[2600]\ttraining's auc: 0.760802\tvalid_1's auc: 0.682863\n",
      "[2650]\ttraining's auc: 0.76203\tvalid_1's auc: 0.683096\n",
      "[2700]\ttraining's auc: 0.76299\tvalid_1's auc: 0.683067\n",
      "[2750]\ttraining's auc: 0.763757\tvalid_1's auc: 0.683125\n",
      "[2800]\ttraining's auc: 0.764768\tvalid_1's auc: 0.683086\n",
      "[2850]\ttraining's auc: 0.76559\tvalid_1's auc: 0.68339\n",
      "[2900]\ttraining's auc: 0.766484\tvalid_1's auc: 0.683616\n",
      "[2950]\ttraining's auc: 0.767585\tvalid_1's auc: 0.683811\n",
      "[3000]\ttraining's auc: 0.768655\tvalid_1's auc: 0.683941\n",
      "[3050]\ttraining's auc: 0.769532\tvalid_1's auc: 0.683942\n",
      "[3100]\ttraining's auc: 0.77059\tvalid_1's auc: 0.684022\n",
      "[3150]\ttraining's auc: 0.771502\tvalid_1's auc: 0.684112\n",
      "[3200]\ttraining's auc: 0.772329\tvalid_1's auc: 0.683926\n",
      "[3250]\ttraining's auc: 0.773098\tvalid_1's auc: 0.68394\n",
      "[3300]\ttraining's auc: 0.773911\tvalid_1's auc: 0.684216\n",
      "[3350]\ttraining's auc: 0.77482\tvalid_1's auc: 0.684199\n",
      "[3400]\ttraining's auc: 0.775546\tvalid_1's auc: 0.684283\n",
      "[3450]\ttraining's auc: 0.776426\tvalid_1's auc: 0.684424\n",
      "[3500]\ttraining's auc: 0.776904\tvalid_1's auc: 0.684381\n",
      "[3550]\ttraining's auc: 0.777721\tvalid_1's auc: 0.684425\n",
      "[3600]\ttraining's auc: 0.778441\tvalid_1's auc: 0.684618\n",
      "[3650]\ttraining's auc: 0.779226\tvalid_1's auc: 0.684454\n",
      "[3700]\ttraining's auc: 0.780123\tvalid_1's auc: 0.684483\n",
      "[3750]\ttraining's auc: 0.780863\tvalid_1's auc: 0.684328\n",
      "Early stopping, best iteration is:\n",
      "[3594]\ttraining's auc: 0.778415\tvalid_1's auc: 0.684638\n",
      "Fold 10 AUC : 0.684638\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds = StratifiedKFold(n_splits= 10, shuffle=True, random_state=666)\n",
    "\n",
    "oof_preds = np.zeros(X.shape[0])\n",
    "sub_preds = np.zeros(rx.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, Y)):\n",
    "\n",
    "    train_x, train_y = X[train_idx,:], Y[train_idx]\n",
    "    valid_x, valid_y = X[valid_idx,:], Y[valid_idx]\n",
    "\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 8, 'boosting_type': 'dart','objective': 'regression', 'metric': 'auc', \n",
    "        'learning_rate': 0.01, 'num_leaves': 70,\n",
    "    'max_depth': 10, 'subsample': 0.2, 'feature_fraction': 0.2, \n",
    "        'min_split_gain': 0.09, 'min_child_weight': 9.5,\n",
    "        'min_data_in_leaf':10,\n",
    "        'bagging_freq':5,\n",
    "    'drop_rate':0.5, 'skip_drop':0.5, 'max_drop':5, 'uniform_drop':False, \n",
    "        'xgboost_dart_mode':True, 'drop_seed':1 }\n",
    "\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=10000, valid_sets=[dtrain,dval], early_stopping_rounds=200, verbose_eval=50)\n",
    "\n",
    "\n",
    "        tmp_valid = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        oof_preds[valid_idx] = tmp_valid\n",
    "        sub_preds += bst.predict(rx, num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        \n",
    "\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),'split':bst.feature_importance('split'),\n",
    "                                           'gain':100*gain/gain.sum(),  'fold':n_fold,}).sort_values('gain',ascending=False)\n",
    "\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "\n",
    "        del bst, train_x, train_y, valid_x, valid_y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanMapping(x):\n",
    "    if np.isnan(x):\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "app_test = pd.read_csv('testing-set.csv', usecols=['order_id'])\n",
    "predF=pd.DataFrame({\"order_id\":rid, \"deal_or_not\":sub_preds})\n",
    "preds = pd.DataFrame({\"order_id\":app_test['order_id']})\n",
    "preds=preds.merge(predF, on=\"order_id\",how=\"outer\")\n",
    "preds['deal_or_not'] = preds.deal_or_not.apply(lambda x: nanMapping(x))\n",
    "preds.to_csv(\"output/lgb_dart_\" + str(roc_auc_score(Y, oof_preds)) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, ElasticNet\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from catboost import Pool, CatBoostRegressor, cv\n",
    "\n",
    "\n",
    "len1 = len(Y)\n",
    "tind = np.zeros(len1, np.int)\n",
    "for i in range(len1):\n",
    "    tind[i]=i\n",
    "import random as rn\n",
    "rn.Random(4).shuffle(tind)\n",
    "print(train_x.shape)\n",
    "\n",
    "train_x, train_y = X[tind[1000:],:], Y[tind[1000:]]\n",
    "valid_x, valid_y = X[tind[:1000],:], Y[tind[:1000]]\n",
    "\n",
    "model_ridge = Ridge(alpha = 5)\n",
    "model_ridge.fit(train_x, train_y)\n",
    "\n",
    "model_lasso = Lasso(alpha = 0.005)\n",
    "model_lasso.fit(train_x, train_y)\n",
    "\n",
    "model_en = ElasticNet(alpha = 0.005)\n",
    "model_en.fit(train_x, train_y)\n",
    "\n",
    "model_gbr = GradientBoostingRegressor(n_estimators=1200, \n",
    "                                      learning_rate=0.05,\n",
    "                                      max_depth=4, \n",
    "                                      max_features='sqrt',\n",
    "                                      min_samples_leaf=15, \n",
    "                                      min_samples_split=10, \n",
    "                                      loss='huber',\n",
    "                                      random_state=5)\n",
    "model_gbr.fit(train_x, train_y)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.2,\n",
    "                             learning_rate=0.06,\n",
    "                             max_depth=3,\n",
    "                             n_estimators=1150)\n",
    "model_xgb(train_x, train_y)\n",
    "\n",
    "\n",
    "params = {\n",
    "'nthread': 8, 'boosting_type': 'dart','objective': 'regression', 'metric': 'auc', \n",
    "'learning_rate': 0.01, 'num_leaves': 70,\n",
    "'max_depth': 9, 'subsample': 0.9, 'feature_fraction': 0.9, \n",
    "'min_split_gain': 0.09, 'min_child_weight': 9.5,\n",
    "'drop_rate':0.5, 'skip_drop':0.5, 'max_drop':5, 'uniform_drop':False, \n",
    "'xgboost_dart_mode':True, 'drop_seed':5 }\n",
    "\n",
    "dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "bst = lgb.train(params, dtrain, num_boost_round=15000, valid_sets=[dval], early_stopping_rounds=2500, \n",
    "                verbose_eval=500)\n",
    "\n",
    "tmp_valid = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "sub_preds = bst.predict(rx, num_iteration=bst.best_iteration) \n",
    "\n",
    "# Make the feature importance dataframe\n",
    "print('AUC : %.6f' % (roc_auc_score(valid_y, tmp_valid)))\n",
    "def nanMapping(x):\n",
    "    if np.isnan(x):\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "app_test = pd.read_csv('testing-set.csv', usecols=['order_id'])\n",
    "predF=pd.DataFrame({\"order_id\":rid, \"deal_or_not\":sub_preds})\n",
    "preds = pd.DataFrame({\"order_id\":app_test['order_id']})\n",
    "preds=preds.merge(predF, on=\"order_id\",how=\"outer\")\n",
    "preds['deal_or_not'] = preds.deal_or_not.apply(lambda x: nanMapping(x))\n",
    "preds.to_csv(\"output/lgb_dart_\" + str(roc_auc_score(valid_y, tmp_valid)) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['deal_or_not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
